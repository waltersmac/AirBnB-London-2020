{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "PROJECT_NAME = \"AirBnB-London-2020\"\n",
    "IMAGES_PATH = \"../reports/figures/\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings = pd.read_csv('../data/raw/listings.csv', dtype={'listing_url': 'object',\n",
    "                                                      'price': 'object',\n",
    "                                                      'weekly_price': 'object',\n",
    "                                                      'monthly_price': 'object',\n",
    "                                                      'security_deposit': 'object',\n",
    "                                                      'cleaning_fee': 'object',\n",
    "                                                      'extra_people': 'object',\n",
    "                                                      'license': 'object', \n",
    "                                                      'jurisdiction_names': 'object',})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# show listings data sample\n",
    "df_listings.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class format_data:\n",
    "    \n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "        \n",
    "    def data_float(self):\n",
    "        self = self.str.replace('$', '', regex=True).replace(',', '', regex=True).astype(float)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def data_percentage(self):\n",
    "        self = (self.str.replace('%', '', regex=True).astype('float')) / 100\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def dict_to_list(self):\n",
    "        self = self.str.replace('{', '', regex=True).replace('}', '', regex=True).replace('\\\"', '', regex=True)\n",
    "        self = self.str.split(',')\n",
    "              \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_list = ['price','security_deposit','cleaning_fee','extra_people']\n",
    "for x in float_list:\n",
    "    df_listings[x] = format_data.data_float(df_listings[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_list = ['host_response_rate','host_acceptance_rate']\n",
    "for x in float_list:\n",
    "    df_listings[x] = format_data.data_percentage(df_listings[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings['amenities'] = format_data.dict_to_list(df_listings['amenities'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings.hist(bins=50, figsize=(30,30))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_listings.columns[df_listings.isnull().mean()>0.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Price Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers(df_listings):\n",
    "    # Calculate Q1 (25th percentile of the data) for the given feature\n",
    "    Q1 = np.percentile(df_listings[\"price\"], 25)\n",
    "    \n",
    "    #Calculate Q3 (75th percentile of the data) for the given feature\n",
    "    Q3 = np.percentile(df_listings[\"price\"],75)\n",
    "    \n",
    "    # Use the interquartile range to calculate an outlier step (1.5 times the interquartile range)\n",
    "    step = (Q3 - Q1) * 1.5\n",
    "    \n",
    "    # Display the outliers\n",
    "    #print(\"Data points considered outliers for the feature '{}':\".format(\"price\"))\n",
    "    filtered_data = df_listings[~((df_listings[\"price\"] >= Q1 - step) & \n",
    "                                  (df_listings[\"price\"] <= Q3 + step))].sort_values(by=[\"price\"])\n",
    "                                  \n",
    "    #filtered_data[\"price\"].hist()\n",
    "    #outliers = filtered_data[filtered_data[\"price\"] >= 1000.00]\n",
    "    \n",
    "    return filtered_data\n",
    "                                  \n",
    "                                  \n",
    "outliers = find_outliers(df_listings).index\n",
    "                                  \n",
    "df_listings = df_listings.drop(df_listings.index[outliers]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings[\"price\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhood_vals = df_listings['property_type'].value_counts()\n",
    "\n",
    "# The below should be a bar chart of the proportion of individuals in each professional category if your status_vals\n",
    "# is set up correctly.\n",
    "\n",
    "((neighbourhood_vals[0:5]/df_listings.shape[0]).sort_values()).plot(kind=\"barh\");\n",
    "plt.title(\"Top 5 type of properties, that are most advertised\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_vals = df_listings['room_type'].value_counts()\n",
    "\n",
    "# The below should be a bar chart of the proportion of individuals in each professional category if your status_vals\n",
    "# is set up correctly.\n",
    "\n",
    "((room_vals/df_listings.shape[0]).sort_values()).plot(kind=\"barh\");\n",
    "plt.title(\"The type of rooms, are most advertised\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings.plot(kind='scatter', x='longitude', y='latitude', alpha=0.4, figsize=(15,10),\n",
    "                 s=(df_listings[\"availability_365\"])/100, label=\"availability_365\", \n",
    "                 c=\"price\", cmap=plt.get_cmap('jet'), \n",
    "                 colorbar=True,\n",
    "                 sharex=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "# pip Install descartes\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15,10))\n",
    "\n",
    "basemap = gpd.read_file('../data/external/statistical-gis-boundaries-london/ESRI/London_Borough_Excluding_MHW.shp')\n",
    "basemap = basemap.to_crs(epsg=4326)\n",
    "\n",
    "\n",
    "basemap = basemap.plot(alpha=0.5, edgecolor='k',color='White',figsize=(15,10),ax=ax)\n",
    "basemap.set_facecolor('black')\n",
    "\n",
    "\n",
    "x, y = df_listings['longitude'].values, df_listings['latitude'].values\n",
    "basemap.scatter(x,y, alpha=0.5,\n",
    "                 s=(df_listings[\"availability_365\"])/100, label=\"availability_365\", \n",
    "                 c=df_listings[\"price\"], cmap=plt.get_cmap('jet'))\n",
    "\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=plt.get_cmap('jet'))\n",
    "prices = df_listings[\"price\"]\n",
    "tick_values = np.linspace(prices.min(), prices.max(), 11)\n",
    "cbar = fig.colorbar(sm, ticks=tick_values/prices.max(), alpha=0.5)\n",
    "cbar.ax.set_yticklabels([\"Â£%d\"% v for v in tick_values], fontsize=10)\n",
    "cbar.set_label('Price Value', fontsize=10)\n",
    "\n",
    "# Removing ticks\n",
    "plt.xticks([]),\n",
    "plt.yticks([])\n",
    "\n",
    "plt.legend(fontsize=10)\n",
    "save_fig(\"availability_365_prices_scatterplot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the average price of the listings, for the different location within London?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df = df_listings[df_listings['price'].isnull() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df['neighbourhood_cleansed'].value_counts()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_price_avg = price_df.groupby('neighbourhood_cleansed', as_index=False).mean()\n",
    "nb_price_avg = pd.DataFrame(nb_price_avg).sort_values(by='price', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_price_avg = nb_price_avg.rename(columns={'neighbourhood_cleansed':'Neighbourhood','price': 'Avg Price'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart_plot(data, x_label, y_label):\n",
    "    \n",
    "    plt.figure(figsize=(10,5))\n",
    "\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    chart = sns.barplot(x=x_label, y=y_label, data=data)\n",
    "\n",
    "    chart.set_xticklabels(\n",
    "        chart.get_xticklabels(), \n",
    "        rotation=60, \n",
    "        horizontalalignment='right',\n",
    "        fontweight='light',\n",
    "        fontsize='medium', \n",
    "        rotation_mode='anchor'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_plot(nb_price_avg,\"Neighbourhood\", \"Avg Price\")\n",
    "save_fig(\"Neighbourhood_av_price_histogram_plots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What types of verifications are hosts using? How long did it take them to respond?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verifications_df = df_listings[df_listings['host_verifications'].isnull() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verifications_df = verifications_df[verifications_df['host_verifications'] != '[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifications_types(column):\n",
    "    verifications_dict = {}\n",
    "    temp = []\n",
    "\n",
    "    for i in column:\n",
    "        temp.append(eval(i))\n",
    "    \n",
    "    for i in temp:\n",
    "        try:\n",
    "            for j in i:\n",
    "                if j not in verifications_dict:\n",
    "                    verifications_dict[j] = 1\n",
    "                else:\n",
    "                    verifications_dict[j] += 1\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    return verifications_dict\n",
    "        \n",
    "verifications_types = verifications_types(verifications_df['host_verifications'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in verifications_types.items():\n",
    "    verifications_types[k] = round(v / verifications_df.shape[0] * 100, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verifications_types = pd.DataFrame.from_dict(verifications_types,orient='index',columns=['A']).reset_index()\n",
    "verifications_types = verifications_types.rename(columns={'index':'Verification Type','A': '% of listings'})\n",
    "top10_verifications_types = verifications_types.sort_values(by='% of listings', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_plot(top10_verifications_types,\"Verification Type\", \"% of listings\")\n",
    "save_fig(\"Verification_type_price_histogram_plots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What amenities are most used and does the count of amenities affect the review? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left = df_listings[['id','amenities']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_right = df_listings[['id','review_scores_value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left = df_left.amenities.apply(pd.Series).merge(df_left, right_index = True, \n",
    "                                         left_index = True) \\\n",
    "                                  .drop([\"amenities\"], axis = 1) \\\n",
    "                                  .melt(id_vars = ['id'], value_name = \"amenities\") \\\n",
    "                                  .drop(\"variable\", axis = 1) \\\n",
    "                                  .dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(df_left, df_right, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.groupby('amenities').agg({'review_scores_value': ['count', 'min', 'max', 'mean']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.sort_values(by=[('review_scores_value', 'mean'),\n",
    "                                ('review_scores_value',  'min'),\n",
    "                                ('review_scores_value',  'max')], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.columns = [\"_\".join(x) for x in result.columns.ravel()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.rename(columns={\"amenities_\":\"Amenities\", \n",
    "                       \"review_scores_value_count\":\"Count Listings\",\n",
    "                       \"review_scores_value_min\":\"Review Min Value\",\n",
    "                       \"review_scores_value_max\":\"Review Max Value\",\n",
    "                       \"review_scores_value_mean\":\"Review Avg Value\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result[result['Count Listings'] > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.head(20).style.background_gradient() \\\n",
    "               .format({\"Amenities\": lambda x:x.lower()}) \\\n",
    "               .format({\"Review Min Value\": \"{:20,.2f}\"}) \\\n",
    "               .format({\"Review Max Value\": \"{:20,.2f}\"}) \\\n",
    "               .format({\"Review Avg Value\": \"{:20,.2f}\"}) \\\n",
    "               .hide_index()\\\n",
    "               .background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.set_properties(subset=[\"Amenities\", \n",
    "                              \"Count Listings\", \n",
    "                              \"Review Min Value\", \n",
    "                              \"Review Max Value\", \n",
    "                              \"Review Avg Value\"], **{'text-align': 'left'}) \\\n",
    "      .set_table_styles([dict(selector='th', props=[('text-align', 'left')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataframe_image as dfi\n",
    "dfi.export(result, '../reports/figures/top_amenities.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What features assist in the pricing of a listing? \n",
    "- Could the price be predicted?\n",
    "- importance of the features, rank features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the 'amenities - count' column\n",
    "df_listings['amenities - count'] = [len(i) for i in df_listings['amenities']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na_data(df_listings):\n",
    "    \n",
    "    # filling float or int columns with the mean value of the column\n",
    "    num_vars = df_listings.select_dtypes(include=['float', 'int']).columns\n",
    "    for col in num_vars:\n",
    "        df_listings[col].fillna((df_listings[col].mean()), inplace=True)\n",
    "        \n",
    "        \n",
    "    # filling the categorial columns with text\n",
    "    df_listings['host_response_time'].fillna('No Response', inplace=True)\n",
    "    df_listings['host_is_superhost'].fillna('f', inplace=True)\n",
    "    df_listings['host_has_profile_pic'].fillna('f', inplace=True)\n",
    "    df_listings['bed_type'].fillna('Unknown', inplace=True)\n",
    "    \n",
    "    return df_listings\n",
    "\n",
    "df_listings = fill_na_data(df_listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df_listings):\n",
    "    \n",
    "    # Dropping Columns that aren't needed\n",
    "    regex_list = ['url','id','scraped','first_review','last_review']\n",
    "    for i in regex_list:\n",
    "        df_listings = df_listings[df_listings.columns.drop(list(df_listings.filter(regex=i)))]\n",
    "        \n",
    "    df_listings = df_listings.drop(columns=['name','summary','space','description','neighborhood_overview','notes',\n",
    "                                            'transit','access','interaction','house_rules','host_name','host_about',\n",
    "                                            'latitude','longitude','host_since','host_neighbourhood','street',\n",
    "                                            'neighbourhood','market','host_location','city','state','zipcode',\n",
    "                                            'smart_location','country_code','country','amenities', 'host_verifications'])\n",
    "    \n",
    "    # remove columns with 70% or high with missing data\n",
    "    col_nulls = set(df_listings.columns[df_listings.isnull().mean()>0.70])\n",
    "    df_listings = df_listings.drop(list(col_nulls), axis=1)\n",
    "    \n",
    "    return df_listings\n",
    "\n",
    "df_listings = drop_columns(df_listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing rows that do not have a price\n",
    "# df = df_listings.dropna(subset=[\"price\"])\n",
    "df = df_listings[df_listings['price'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy the categorical variables\n",
    "cat_vars = df.select_dtypes(include=['object']).copy().columns\n",
    "for var in  cat_vars:\n",
    "    # for each cat add dummy var, drop original column\n",
    "    df = pd.concat([df.drop(var, axis=1), pd.get_dummies(df[var],\n",
    "                                                         prefix=var, prefix_sep='_', drop_first=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and labels\n",
    "features = df.drop('price', axis = 1)\n",
    "labels = df['price']\n",
    "\n",
    "# List of features for later use\n",
    "feature_list = list(features.columns)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_selection import SelectKBest\n",
    "#from sklearn.feature_selection import f_regression\n",
    "#fs = SelectKBest(score_func=f_regression, k=200)\n",
    "\n",
    "#X_selected = fs.fit_transform(X, y)\n",
    "#print(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Features Shape:', X_train.shape)\n",
    "print('Training Labels Shape:', y_train.shape)\n",
    "print('Testing Features Shape:', X_test.shape)\n",
    "print('Testing Labels Shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fittng the training data with various models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(model,X_train,y_train):\n",
    "    \n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rmse(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test) \n",
    "    mse = mean_squared_error(y_test,predictions) \n",
    "    rmse = np.sqrt(mse) \n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accurancy(model, X_test, y_test):\n",
    "    \n",
    "    # Make predictions on test data using the model trained on original data\n",
    "    predictions = model.predict(X_test) \n",
    "    \n",
    "    # Performance metrics\n",
    "    errors = abs(y_test - predictions)\n",
    "    \n",
    "    # Average absolute error metric\n",
    "    print('Average absolute error:', round(np.mean(errors), 2), 'degrees.')\n",
    "    \n",
    "    # Calculate mean absolute percentage error (MAPE)\n",
    "    mape = 100 * (errors / y_test)\n",
    "    \n",
    "    # Calculate and display accuracy\n",
    "    accuracy = 100 - np.mean(mape)\n",
    "    \n",
    "    print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "lin_reg = LinearRegression()\n",
    "model_fit(lin_reg, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression - RMSE\n",
    "model_rmse(lin_reg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression - model accurancy\n",
    "model_accurancy(lin_reg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regression\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "model_fit(tree_reg, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regression - RMSE\n",
    "model_rmse(tree_reg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regression - model_accurancy\n",
    "model_accurancy(tree_reg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "model_fit(forest_reg, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regression - RMSE\n",
    "model_rmse(forest_reg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regression - modelmodel_accurancyrancyy\n",
    "model_accurancy(forest_reg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the scores, mean and standard variations of the different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(model,X_train,y_train):\n",
    "    \n",
    "    scores = cross_val_score(model,X_train,y_train,scoring = \"neg_mean_squared_error\",cv = 10, n_jobs=-1)\n",
    "    model_rmse_scores = np.sqrt(-scores) \n",
    "    \n",
    "    print(\"Scores:\",model_rmse_scores)\n",
    "    print(\"Mean:\",model_rmse_scores.mean())\n",
    "    print (\"Standard deviation:\",model_rmse_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "display_scores(lin_reg,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regression\n",
    "display_scores(tree_reg,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regression\n",
    "display_scores(forest_reg,X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Number of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def open_file(file_name):\n",
    "    \n",
    "    open_file = open(file_name, \"rb\")\n",
    "    my_results, my_names = pickle.load(open_file)\n",
    "    open_file.close()\n",
    "    \n",
    "    for name, scores in zip(my_names, my_results):\n",
    "        # summarize the performance along the way\n",
    "        print('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n",
    "       \n",
    "    return my_results, my_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot model performance for comparison\n",
    "plt.boxplot(my_results, labels=my_names, showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Number of Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_results, tree_names = open_file(\"eval_tree_models.pickle\")\n",
    "\n",
    "# plot model performance for comparison\n",
    "plt.boxplot(tree_results, labels=tree_names, showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Tree Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_results, depth_names = open_file(\"eval_depth_models.pickle\")\n",
    "\n",
    "# plot model performance for comparison\n",
    "plt.boxplot(depth_results, labels=depth_names, showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV - Finding the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the trained model \n",
    "with open(\"../models/final_model.pickle\", 'rb') as handle:\n",
    "    final_model = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = final_model.best_params_\n",
    "cv_results = final_model.cv_results_\n",
    "feature_importances = final_model.best_estimator_._final_estimator.feature_importances_\n",
    "final_model = final_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the feature importance\n",
    "# feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the feature importance scores\n",
    "# extra_attribs = [\"rooms_per_hhold\",\"pop_per_hhold\",\"bedrooms_per_room\"]\n",
    "# cat_encoder = full_pipeline.named_transformers_ [\"cat\"]\n",
    "# cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "# attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
    "sorted(zip(feature_importances,X_train.columns),reverse = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = final_model.cv_results_\n",
    "\n",
    "for mean_score, params in zip (cv_results[\"mean_test_score\"], cv_results[\"params\"]):\n",
    "    print(round(np.sqrt(-mean_score),2),params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the system on the test set\n",
    "model_rmse(final_model, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
